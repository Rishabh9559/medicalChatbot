{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94428f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16407 records\n",
      "   id                                           question  \\\n",
      "0   1  Who is at risk for Lymphocytic Choriomeningiti...   \n",
      "1   2  What are the symptoms of Lymphocytic Choriomen...   \n",
      "\n",
      "                                              answer      source  \n",
      "0  LCMV infections can occur after exposure to fr...  medDataset  \n",
      "1  LCMV is most commonly recognized as causing ne...  medDataset  \n",
      "Parsed 16407 rows\n",
      "   id                                           question  \\\n",
      "0   1  Who is at risk for Lymphocytic Choriomeningiti...   \n",
      "1   2  What are the symptoms of Lymphocytic Choriomen...   \n",
      "\n",
      "                                              answer      source  \n",
      "0  LCMV infections can occur after exposure to fr...  medDataset  \n",
      "1  LCMV is most commonly recognized as causing ne...  medDataset  \n",
      "Parsed 16407 rows\n",
      "Smoke Test Result: {'category': 'viral infection', 'entities': ['lymphocytic choriomeningitis', 'lymphocytic choriomeningitis virus', 'rodent', 'fetus', 'organ transplant recipient'], 'keywords': ['LCMV', 'rodent', 'transmission', 'exposure', 'vertical', 'fetus', 'organ transplant', 'risk', 'choriomeningitis'], 'safety_level': 'medium'}\n",
      "Starting concurrent enrichment with 50 workers...\n",
      "Smoke Test Result: {'category': 'viral infection', 'entities': ['lymphocytic choriomeningitis', 'lymphocytic choriomeningitis virus', 'rodent', 'fetus', 'organ transplant recipient'], 'keywords': ['LCMV', 'rodent', 'transmission', 'exposure', 'vertical', 'fetus', 'organ transplant', 'risk', 'choriomeningitis'], 'safety_level': 'medium'}\n",
      "Starting concurrent enrichment with 50 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enriching Records: 100%|██████████| 16407/16407 [1:07:37<00:00,  4.04it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                           question  \\\n",
      "0   1  Who is at risk for Lymphocytic Choriomeningiti...   \n",
      "1   2  What are the symptoms of Lymphocytic Choriomen...   \n",
      "\n",
      "                                              answer      source  \\\n",
      "0  LCMV infections can occur after exposure to fr...  medDataset   \n",
      "1  LCMV is most commonly recognized as causing ne...  medDataset   \n",
      "\n",
      "          category                                           entities  \\\n",
      "0  viral infection  [lymphocytic choriomeningitis, lymphocytic cho...   \n",
      "1  viral infection  [Lymphocytic Choriomeningitis Virus, Lymphocyt...   \n",
      "\n",
      "                                            keywords safety_level  char_count  \\\n",
      "0  [LCMV, lymphocytic choriomeningitis, transmiss...       medium         466   \n",
      "1  [LCMV, symptoms, neurological, febrile, mening...         high        2468   \n",
      "\n",
      "                                       combined_text error  \n",
      "0  Question: Who is at risk for Lymphocytic Chori...   NaN  \n",
      "1  Question: What are the symptoms of Lymphocytic...   NaN  \n",
      "Enriched 16407 rows\n",
      "Saved:\n",
      " - enriched\\enriched_records.json (54766.0 KB)\n",
      " - enriched\\enriched_records.jsonl (52032.8 KB)\n",
      " - enriched\\enriched_records.csv (50057.0 KB)\n",
      " - enriched\\metadata_prefixed_corpus.txt (26899.2 KB)\n",
      "Saved:\n",
      " - enriched\\enriched_records.json (54766.0 KB)\n",
      " - enriched\\enriched_records.jsonl (52032.8 KB)\n",
      " - enriched\\enriched_records.csv (50057.0 KB)\n",
      " - enriched\\metadata_prefixed_corpus.txt (26899.2 KB)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, json, re, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --- Configuration and Setup ---\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\") \n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in environment (.env)\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "OUTPUT_DIR = Path(\"enriched\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "RAW_JSON_PATH = Path(\"data.json\")\n",
    "if not RAW_JSON_PATH.exists():\n",
    "    raise FileNotFoundError(\"data.json not found in workspace root\")\n",
    "\n",
    "with RAW_JSON_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    raw_records = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(raw_records)} records\")\n",
    "raw_records[:1]\n",
    "\n",
    "\n",
    "# xtract question & answer from QA_Data\n",
    "\n",
    "def parse_qa(text: str):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    q_part, a_part = \"\", \"\"\n",
    "    m = re.match(r\"(?i)question:\\s*(.+?)\\s*answer:\\s*(.+)$\", cleaned)\n",
    "    if m:\n",
    "        q_part = m.group(1).strip()\n",
    "        a_part = m.group(2).strip()\n",
    "    else:\n",
    "        \n",
    "        if \"Answer:\" in text:\n",
    "            parts = text.split(\"Answer:\", 2)\n",
    "            q_part = parts[0].replace(\"Question:\", \"\").strip()\n",
    "            a_part = parts[1].strip()\n",
    "        else:\n",
    "            q_part = cleaned[:200]\n",
    "            a_part = cleaned\n",
    "    # Collapse duplicate question marks\n",
    "    q_part = re.sub(r\"\\?{2,}\", \"?\", q_part)\n",
    "    return q_part, a_part\n",
    "\n",
    "parsed_rows = []\n",
    "for idx, rec in enumerate(raw_records, start=1):\n",
    "    qa_text = rec.get(\"QA_Data\", \"\")\n",
    "    q, a = parse_qa(qa_text)\n",
    "    parsed_rows.append({\n",
    "        \"id\": idx,\n",
    "        \"question\": q,\n",
    "        \"answer\": a,\n",
    "        \"source\": \"medDataset\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(parsed_rows)\n",
    "print(df.head(2))\n",
    "print(\"Parsed\", len(df), \"rows\")\n",
    "len(df)\n",
    "\n",
    "\n",
    "SYSTEM_METADATA_PROMPT = (\n",
    "    \"You are a medical data annotator. Given a question and answer, produce concise structured JSON with: \"\n",
    "    \"category (lowercase short topic), entities (list of unique medical entities: diseases, syndromes, pathogens, drugs, symptoms, risk groups), \"\n",
    "    \"keywords (5-10 short tokens), safety_level (low|medium|high based on potential harm, pregnancy risk, biohazard, or clinical advice).\"\n",
    ")\n",
    "\n",
    "GENERATION_SCHEMA_EXAMPLE = {\n",
    "    \"category\": \"viral infection\",\n",
    "    \"entities\": [\"lymphocytic choriomeningitis virus\", \"rodent\", \"meningitis\"],\n",
    "    \"keywords\": [\"LCMV\", \"rodent\", \"meningitis\", \"encephalitis\", \"transmission\"],\n",
    "    \"safety_level\": \"medium\"\n",
    "}\n",
    "\n",
    "def build_prompt(question: str, answer: str) -> str:\n",
    "    return (\n",
    "        f\"Question: {question}\\nAnswer: {answer}\\n---\\n\"\n",
    "        f\"Return ONLY valid minified JSON matching this example shape: {json.dumps(GENERATION_SCHEMA_EXAMPLE, ensure_ascii=False)}\"\n",
    "    )\n",
    "\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "def call_gemini(question: str, answer: str, retries: int = 3, delay: float = 2.0) -> Dict[str, Any]:\n",
    "    prompt = SYSTEM_METADATA_PROMPT + \"\\n\" + build_prompt(question, answer)\n",
    "    last_err: Optional[Exception] = None\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            resp = model.generate_content(prompt)\n",
    "            text = resp.text.strip()\n",
    "            json_candidate = text\n",
    "            json_candidate = re.sub(r'^```json|^```|```$', '', json_candidate.strip(), flags=re.IGNORECASE|re.MULTILINE)\n",
    "            parsed = json.loads(json_candidate)\n",
    "           \n",
    "            for k in [\"category\", \"entities\", \"keywords\", \"safety_level\"]:\n",
    "                if k not in parsed:\n",
    "                    raise ValueError(f\"Missing key {k}\")\n",
    "            if not isinstance(parsed.get(\"entities\"), list):\n",
    "                parsed[\"entities\"] = []\n",
    "            if not isinstance(parsed.get(\"keywords\"), list):\n",
    "                parsed[\"keywords\"] = []\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(delay * attempt)\n",
    "    return {\"error\": str(last_err), **GENERATION_SCHEMA_EXAMPLE}\n",
    "\n",
    "sample_meta = call_gemini(df.loc[0, 'question'], df.loc[0, 'answer'])\n",
    "print(\"Smoke Test Result:\", sample_meta)\n",
    "\n",
    "\n",
    "def process_row(row: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Helper function to process a single row and call the API.\"\"\"\n",
    "    meta = call_gemini(row['question'], row['answer'])\n",
    "    merged = {**row,\n",
    "              **meta,\n",
    "              'char_count': len(row['answer']),\n",
    "              'combined_text': f\"Question: {row['question']}\\nAnswer: {row['answer']}\"}\n",
    "    return merged\n",
    "\n",
    "\n",
    "MAX_WORKERS = 50 \n",
    "print(f\"Starting concurrent enrichment with {MAX_WORKERS} workers...\")\n",
    "rows_to_process = df.to_dict(orient='records')\n",
    "enriched_rows = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    results = list(tqdm(executor.map(process_row, rows_to_process), \n",
    "                        total=len(rows_to_process), \n",
    "                        desc=\"Enriching Records\"))\n",
    "    enriched_rows.extend(results)\n",
    "\n",
    "edf = pd.DataFrame(enriched_rows)\n",
    "print(edf.head(2))\n",
    "print(\"Enriched\", len(edf), \"rows\")\n",
    "\n",
    "\n",
    "\n",
    "ENRICHED_JSON = OUTPUT_DIR / \"enriched_records.json\"\n",
    "ENRICHED_JSONL = OUTPUT_DIR / \"enriched_records.jsonl\"\n",
    "ENRICHED_CSV = OUTPUT_DIR / \"enriched_records.csv\"\n",
    "TEXT_CORPUS = OUTPUT_DIR / \"metadata_prefixed_corpus.txt\"\n",
    "\n",
    "edf.to_json(ENRICHED_JSON, orient='records', indent=2, force_ascii=False)\n",
    "edf.to_json(ENRICHED_JSONL, orient='records', lines=True, force_ascii=False)\n",
    "edf.to_csv(ENRICHED_CSV, index=False)\n",
    "\n",
    "with TEXT_CORPUS.open('w', encoding='utf-8') as f:\n",
    "    for r in edf.to_dict(orient='records'):\n",
    "        meta_header = {\n",
    "            'id': r['id'],\n",
    "            'category': r.get('category'),\n",
    "            'entities': r.get('entities'),\n",
    "            'keywords': r.get('keywords'),\n",
    "            'safety_level': r.get('safety_level')\n",
    "        }\n",
    "        f.write(json.dumps(meta_header, ensure_ascii=False) + \"\\n\")\n",
    "        f.write(r['combined_text'] + \"\\n\\n\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "for p in [ENRICHED_JSON, ENRICHED_JSONL, ENRICHED_CSV, TEXT_CORPUS]:\n",
    "    print(\" -\", p, f\"({p.stat().st_size/1024:.1f} KB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
